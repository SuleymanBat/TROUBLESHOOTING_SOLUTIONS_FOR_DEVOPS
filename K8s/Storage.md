When it comes to storage in Docker, there are two concepts.First is Storage drivers and secondly Volume driver plugins.We are going to see where and how Docker stores data and how it manages file systems of the containers. 

When you install Docker on a system it creates this folder structure at;

>`` /var/lib/docker``

You have multiple folders under it called AUFS, containers, image volumes, etc. This is where Docker stores all its data by default. When we mention data, its mean files related to images and containers running on Docker host. All files related to containers are stored under the containers folder and the files related to images are stored under the image folder.When Docker build images it builds these in a "layered architecture". Each line of instruction in the Dockerfile creates a new layer in the Docker image with just the changes from the previous layer. For example; 

> ``Dockerfile``

> ``FROM Ubuntu``               (This is LAYER1. Base Ubuntu Layer 120 MB)

>``RUN apt-get update && apt-get -y install python``  (This is Layer2. Changes in apt packages 306 MB)

>``RUN pip install flask flask-mysql``   (Layer3. Changes in pip packages  6,3 MB)

>``COPY . /opt/source-code``          (Layer4.Source code 229 B)

>``ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run``   (Layer5. Update Entrypoint 0 B)

>``docker build Dockerfile -t suleyman/my-custom-app``


The first layer is a base Ubuntu operating system, followed by the second instruction that creates a second layerwhich installs all the APT packages and thenthird instruction creates a third layer which with the Python packages finally fifth layer that updates the entry point of the image. Since each layer only stores the from the previous layer, it is reflected in the size as well.
Docker builds images faster and efficiently saves disc space.It i sapplicable if you were to update your application code. Whenever you update your application code such the app.py in this ase, Docker simply reuses all the previous layers from casche and quickly rebuilds the application image by updating the latest source code. Thus saving us a lot of time during rebuilds and updates. When you run a container based off this image using the docker run command as below;

>``docker run suleyman/my-custom-app``

Docker creates a container based of these layers and creates a new writable layer on top of the image layer. The writable layer is used to store data created by the container such as log files written by the application any temporary files generated by the containeror just any file modified by the user on that container. The life of this layer though is only as long as the container is alive. When the container is destroyed this layer and all of the changes stored in it are also destroyed. The same image layer is shared by all containers created using this image.

If I were to og into the newly created container and say create a new file called "temp.txt" it will create that file in the container layer which is read and write. The files in image layer are "read-only". Meaning you cannot edit anything in those layers in image layers.

WHAT IF WE WISH TO PERSIST THIS DATA?
iF WE WERE WORKING with a database and we would like to preserve the data created by the container we could add a persistent volume to the container.  To do this first create a volume using the docker volume create command. When we run the command like that;

>``docker volume create sulo_volume``

it creates a folder under;

>``/var/lib/docker``

>   ``volumes``

>    ``sulo_volumes``

Then when I run the docker container like that;

> ``docker run -v sulo_volume:/var/lib/mysql mysql``

I could mount this volume inside the docker containers rewrite layer using the "-v" option. This will create a new container and mount the sulo_volume we ceeated into /var/lib/mysql folder inside container.So all data written by the database is in fact storedf on the volume created on the Docker host.Even if container is destroyed data is wtill active. 
There two types of mounts. A volume mounting and a bind mount. Volume mount mounts a volume from the volumes directory and bind mount mounts a directory from any location on the Docker host. 

>``docker run --mount type=bind, source=/data/mysql,target=/var/lib/mysql mysql``

Docker uses "storage devices" to enable layered architecture. Storage drivers (AUFS, ZFS, BTRFS,DEVICE MAPPER, OVERLAY) help manage storage on images and containers. If you want to persist storage, you must create volumes. Volumes are not handled by storage drivers. Volumes are handled by volume driver plugins. The default volume driver plugin is "local". The local volume plugin helps create a volume on the Docker host and store its data under the var/lib/docker volumes directory. When you run docker container you can choose to use a specific "volume driver" such as the "rexray EBS" to provision a volume from Amazon EBS. Like that;

>``docker run -it --name mysql --volume-driver rexray/ebs --mount src=ebs-vol,target=/var/lib/mysql mysql``

This will create a container and attach a volume from the AWS Cloud.

Container runtime interface(CRI) is a standard that defines how an orchestration solution like Kubernetes would communicate with "container run times" like Docker. To extent support for different networking solutions,"the container networking interface" was introduced. Now any new networking vendors could simply develop their plugin based on the CNI standards and make their solution work with Kubernetes. "The container storage interface"(CSI) was developed to support to support multiple storage solutions.With CS, you can now write your own drivers for your own storage to work with Kubernetes.

### ![VISUAL PICTURE ABOUT CSI-CNI-CRI ](https://github.com/SuleymanBat/TROUBLESHOOTING_SOLUTIONS_FOR_DEVOPS/blob/b0f9acb2fc5b215a49ec641f6feaf0eb4b309f1a/K8s/CSI-CRI-CNI.PNG)


